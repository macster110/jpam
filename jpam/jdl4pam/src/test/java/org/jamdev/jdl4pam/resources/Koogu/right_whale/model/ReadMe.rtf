{\rtf1\ansi\ansicpg1252\cocoartf2706
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs32 \cf2 \cb3 \expnd0\expndtw0\kerning0
Regarding the metadata file, your example didn't have a case for raw audio inputs, so I'm not sure how to specify metadata for a Koogu model. Basically, all one needs to pass as inputs to the model are fixed size clips. This model expects 2.25 s long clips of audio sampled at 1000 Hz (so 2250 points per clip). That's all is needed in terms of config. The model handles internally any/all necessary transformations including waveform normalization, conversion to spectrogram, band-limiting, etc. I'm assuming (more of hoping) that PAMGuard has a mode which supports simply passing audio waveforms as model inputs.\
}